---
- type: model
  name: GodziLLa 2
  organization: Maya Philippines
  description: GodziLLa 2 is an experimental combination of various proprietary
    LoRAs from Maya Philippines and Guanaco LLaMA 2 1K dataset, with LLaMA 2.
  created_date: 2023-08-11
  url: https://huggingface.co/MayaPH/GodziLLa2-70B
  model_card: https://huggingface.co/MayaPH/GodziLLa2-70B
  modality: text; text
  analysis: Evaluated on the OpenLLM leaderboard, releasing at rank number 4 on
    the leaderboard.
  size: 70B parameters (dense)
  dependencies: [LLaMA 2, Guanaco LLaMA dataset]
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: ''
  access: open
  license: LLaMA 2
  intended_uses: ''
  prohibited_uses: ''
  monitoring: unknown
  feedback: none
- type: model
  name: voyage-code-3
  organization: Voyage AI
  description: "Introducing voyage-code-3, our next-generation embedding model optimized for code retrieval."
  created_date: 2024-12-04
  url: https://blog.voyageai.com/2024/12/04/voyage-code-3/
  model_card: unknown
  modality: unknown
  analysis: "We evaluated voyage-code-3 using an enhanced suite of evaluation datasets designed to address the shortcomings of existing benchmarks and deliver practical, robust results."
  size: unknown
  dependencies: []
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: unknown
  access:
    explanation: "The first 200 million tokens are free."
    value: limited
  license: unknown
  intended_uses: "optimized for code retrieval"
  prohibited_uses: unknown
  monitoring: unknown
  feedback: "If you’re also interested in fine-tuned embedding models, we’d love to hear from you—please email us at contact@voyageai.com."

