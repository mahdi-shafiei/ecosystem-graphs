---
- type: model
  name: Voice Safety Classifier
  organization: Roblox
  description: A large classification model for toxicity detection in voice chats.
    The model is trained on a manually curated real-world dataset comprising 2,374
    hours of voice chat audio clips and was fine-tuned from the WavLM base plus
    it offers. It classifies each piece of content across multiple labels such as
    Profanity, DatingAndSexting, Racist, Bullying, Other, NoViolation.
  created_date: 2024-09-08
  url: https://huggingface.co/Roblox/voice-safety-classifier
  model_card: https://huggingface.co/Roblox/voice-safety-classifier
  modality: Audio; Text
  analysis: The model was evaluated on a dataset with human annotated labels containing
    9,795 samples. Binarized average precision is calculated for each of the toxicity
    classes and reaches up to 94.48%.
  size: Unknown
  dependencies:
    - WavLM base plus
    - Python
    - HuggingFace
    - Voice chat audio clips
  training_emissions: Unknown
  training_time: Unknown
  training_hardware: Unknown
  quality_control: Manually curated real-world dataset to reflect actual usage.
    Evaluated using human annotated samples. The model also calculates precision
    for each of the classes.
  access: open
  license: Unknown
  intended_uses: The model is intended to be used for detecting and classifying
    toxicity in voice chat content.
  prohibited_uses: Unknown
  monitoring: Unknown
  feedback: The feedback mechanism was not provided as part of the description.
