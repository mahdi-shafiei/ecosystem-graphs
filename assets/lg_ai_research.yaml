- access: open
  analysis: The model was evaluated extensively across a wide range of public and
    in-house benchmarks. The comparative analysis showed that the performance of EXAONE
    3.0 was competitive in English and excellent in Korean compared to other large
    language models of a similar size.
  created_date: 2024-09-08
  dependencies:
  - MeCab
  description: EXAONE 3.0 is an instruction-tuned large language model developed by
    LG AI Research. It demonstrates notably robust performance across a range of tasks
    and benchmarks. It has been fine-tuned to be capable of complex reasoning and
    has a particular proficiency in Korean. The released 7.8B parameter model is designed
    to promote open research and innovation.
  feedback: Unknown
  intended_uses: The model was intended for non-commercial and research purposes.
    The capabilities of the model allow for use cases that involve advanced AI and
    language processing tasks, particularly in fields requiring proficiency in English
    and Korean.
  license: Unknown
  modality: text; text
  model_card: unknown
  monitoring: Unknown
  name: EXAONE 3.0 Instruction Tuned Language Model
  nationality: South Korea
  organization: LG AI Research
  prohibited_uses: Commercial use is not intended for this model. Its intended use
    is for non-commercial research and innovation.
  quality_control: Extensive pre-training on a diverse dataset, and advanced post-training
    techniques were employed to enhance instruction-following capabilities. The model
    was also trained to fully comply with data handling standards.
  size: 7.8B parameters (dense)
  training_emissions: Unknown
  training_hardware: Unknown
  training_time: Unknown
  type: model
  url: https://arxiv.org/pdf/2408.03541
