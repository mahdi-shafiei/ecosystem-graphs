---
- type: model
  name: EXAONE 3.0 Instruction Tuned Language Model
  organization: LG AI Research
  description: EXAONE 3.0 is an instruction-tuned large language model developed
    by LG AI Research. It demonstrates notably robust performance across a range
    of tasks and benchmarks. It has been fine-tuned to be capable of complex reasoning
    and has a particular proficiency in Korean. The released 7.8B parameter model
    is designed to promote open research and innovation.
  created_date: 2024-09-08
  url: https://arxiv.org/pdf/2408.03541
  model_card: unknown
  modality: text; text
  analysis: The model was evaluated extensively across a wide range of public and
    in-house benchmarks. The comparative analysis showed that the performance of
    EXAONE 3.0 was competitive in English and excellent in Korean compared to other
    large language models of a similar size.
  size: 7.8B parameters (dense)
  dependencies: [MeCab]
  training_emissions: Unknown
  training_time: Unknown
  training_hardware: Unknown
  quality_control: Extensive pre-training on a diverse dataset, and advanced post-training
    techniques were employed to enhance instruction-following capabilities. The
    model was also trained to fully comply with data handling standards.
  access: open
  license: Unknown
  intended_uses: The model was intended for non-commercial and research purposes.
    The capabilities of the model allow for use cases that involve advanced AI and
    language processing tasks, particularly in fields requiring proficiency in English
    and Korean.
  prohibited_uses: Commercial use is not intended for this model. Its intended use
    is for non-commercial research and innovation.
  monitoring: Unknown
  feedback: Unknown
