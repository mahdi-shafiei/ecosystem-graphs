- access:
    explanation: The dataset index is available from [[dataset blog post]](https://laion.ai/blog/laion-400-open-dataset/)
    value: open
  analysis: ''
  created_date:
    explanation: The date the [[blog post]](https://laion.ai/blog/laion-400-open-dataset/)
      was released.
    value: 2021-08-20
  datasheet: https://laion.ai/blog/laion-400-open-dataset/
  dependencies:
  - CLIP
  - CommonCrawl
  description: LAION-400M is a dataset with CLIP-filtered 400 million image-text pairs,
    their CLIP embeddings and kNN indices that allow efficient similarity search.
    This dataset is entirely openly, freely accessible.
  excluded:
    explanation: See [[Dataset and Methods]](https://arxiv.org/pdf/2111.02114.pdf#section.2)
    value: 'Authors apply the following filtering conditions on the WAT files downloaded
      from Common Crawl: "All samples with less than 5 character alt-text length or
      less than 5 KB image size are dropped. Duplicate removal is performed with bloom
      filter based on URL and alt-text. We use CLIP to compute embeddings of the image
      and alt-text. Then we compute the cosine similarity of both embeddings and drop
      all samples with cosine similarity below 0.3. This threshold was selected based
      on human inspections. We use the CLIP embeddings of images and texts to filter
      out illegal contents."

      '
  feedback: ''
  included: ''
  intended_uses: The authors recommend using the dataset "for research purposes" and
    warn that "this large-scale dataset is non-curated. It was built for research
    purposes to enable testing model training on larger scale for broad researcher
    and other interested communities, and is not meant for any real-world production
    or application."
  license:
    explanation: The license is listed on the [[dataset blog post]](https://laion.ai/blog/laion-400-open-dataset/)
    value: CC BY 4.0
  modality: image, text
  monitoring: ''
  name: LAION-400M
  nationality: Germany
  organization: LAION
  prohibited_uses: No uses are explicitly prohibited by the license. Users are warned
    from using LAION-400M for any real-world production or application.
  quality_control:
    explanation: See [[Dataset and Methods]](https://arxiv.org/pdf/2111.02114.pdf#section.2)
    value: The authors use  CLIP embeddings of images and texts to filter out illegal
      contents. They also use CLIP to tag image-text pairs as NSFW. They note that
      less than 1% of images were detected as NSFW, which can be filtered out by an
      user with NSFW tag.
  sample: []
  size: 400M image-text pairs
  type: dataset
  url: https://laion.ai/blog/laion-400-open-dataset/
- access:
    explanation: The dataset index is available from [[dataset blog post]](https://laion.ai/blog/laion-5b/)
    value: open
  analysis: ''
  created_date:
    explanation: The date the [[blog post]](https://laion.ai/blog/laion-5b/) was released.
      Note that the dataset was already compiled earlier, e.g. the Stable Diffusion
      model released earlier was trained on a subset of LAION-5B
    value: 2022-12-12
  datasheet: https://laion.ai/blog/laion-5b/
  dependencies:
  - CLIP
  - mCLIP
  - CommonCrawl
  description: LAION is a dataset of 5 billion image-text pairs from the Internet
  excluded:
    explanation: See [[dataset blog post]](https://laion.ai/blog/laion-5b/)
    value: All samples with less than 5 characters alt-text length or less than 5
      KB image size are dropped. All images with the too big resolution, potentially
      DOS bombs, were dropped before attempting to process them. Duplicate removal
      is performed with a bloom filter based on URL. Future runs would include more
      variate deduplication rules, such as URL + language for the multilanguage dataset.
      We use CLIP respectively MCLIP to compute embeddings of the image and alt-text.
      Then we compute the cosine similarity of both embeddings and drop all samples
      with cosine similarity below 0.28 for the English language ( with CLIP B/32)
      and 0.26 for the multilingual dataset (MCLIP). These thresholds were selected
      based on human inspection of the test results. We use the CLIP embeddings of
      images and texts to filter out to the possible extent the illegal content.
  feedback: ''
  included: ''
  intended_uses: The authors recommend using the dataset "for research purposes" and
    "do not recommend using it for creating ready-to-go industrial products, as the
    basic research about general properties and safety of such large-scale models,
    which we would like to encourage with this release, is still in progress"
  license:
    explanation: The license is listed on the [[dataset blog post]](https://laion.ai/blog/laion-5b/)
    value: CC BY 4.0
  modality: image, text
  monitoring: ''
  name: LAION-5B
  nationality: Germany
  organization: LAION
  prohibited_uses: No uses are explicitly prohibited by the license. Users are warned
    from using LAION-5B for non-research purposes.
  quality_control: ''
  sample: []
  size: 5B image-text pairs
  type: dataset
  url: https://laion.ai/blog/laion-5b/
- access:
    explanation: The dataset index is available from [[dataset blog post]](https://laion.ai/blog/laion-5b/)
    value: open
  analysis: ''
  created_date:
    explanation: The date the [[blog post]](https://laion.ai/blog/laion-5b/) was released.
      Note that the dataset was already compiled earlier, e.g. the Stable Diffusion
      model released earlier was trained on a subset of LAION-5B
    value: 2022-12-12
  datasheet: https://laion.ai/blog/laion-5b/
  dependencies:
  - CLIP
  - LAION-5B
  description: LAION-2B-en is a subset of the LAION-5B dataset and contains 2.3 billion
    English image-text pairs.
  excluded:
    explanation: See [[dataset blog post]](https://laion.ai/blog/laion-5b/)
    value: All samples with less than 5 characters alt-text length or less than 5
      KB image size are dropped. All images with the too big resolution, potentially
      DOS bombs, were dropped before attempting to process them. Duplicate removal
      is performed with a bloom filter based on URL. Future runs would include more
      variate deduplication rules, such as URL + language for the multilanguage dataset.
      We use CLIP respectively MCLIP to compute embeddings of the image and alt-text.
      Then we compute the cosine similarity of both embeddings and drop all samples
      with cosine similarity below 0.28 for the English language ( with CLIP B/32)
      and 0.26 for the multilingual dataset (MCLIP). These thresholds were selected
      based on human inspection of the test results. We use the CLIP embeddings of
      images and texts to filter out to the possible extent the illegal content.
  feedback: ''
  included: ''
  intended_uses: The authors recommend using the dataset "for research purposes" and
    "do not recommend using it for creating ready-to-go industrial products, as the
    basic research about general properties and safety of such large-scale models,
    which we would like to encourage with this release, is still in progress"
  license:
    explanation: The license is listed on the [[dataset blog post]](https://laion.ai/blog/laion-5b/)
    value: CC BY 4.0
  modality: image, text
  monitoring: ''
  name: LAION-2B-en
  nationality: Germany
  organization: LAION
  prohibited_uses: No uses are explicitly prohibited by the license. Users are warned
    from using LAION-2B-en for non-research purposes.
  quality_control: ''
  sample: []
  size: 2.32B image-text pairs
  type: dataset
  url: https://arxiv.org/pdf/2210.08402.pdf
- access: open
  analysis: Evaluated on COCO captioning and VQAv2 vision-language tasks.
  created_date: 2023-03-28
  dependencies:
  - LLaMA
  - CLIP
  description: An open-source reproduction of DeepMind's Flamingo model. At its core,
    OpenFlamingo is a framework that enables training and evaluation of large multimodal
    models (LMMs).
  feedback: ''
  intended_uses: academic research purposes
  license: MIT
  modality: image, text; text
  model_card: https://github.com/mlfoundations/open_flamingo/blob/main/MODEL_CARD.md
  monitoring: ''
  name: OpenFlamingo
  nationality: Germany
  organization: LAION
  prohibited_uses: commercial use
  quality_control: ''
  size: 9B parameters (dense)
  training_emissions: ''
  training_hardware: ''
  training_time: ''
  type: model
  url: https://laion.ai/blog/open-flamingo/
