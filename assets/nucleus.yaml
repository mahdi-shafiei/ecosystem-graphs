- access: open
  analysis: Evaluated on the OpenLLM leaderboard, performing on par with similar-sized
    models.
  created_date: 2023-10-05
  dependencies:
  - RefinedWeb
  description: Nucleus is a 22B parameters causal decoder-only model built by Nucleus.AI
    and trained on 500B tokens of RefinedWeb along with curated corpora.
  feedback: https://huggingface.co/NucleusAI/nucleus-22B-token-500B/discussions
  intended_uses: Research on large language models; as a foundation for further specialization
    and finetuning for specific usecases (e.g., summarization, text generation, chatbot,
    etc.)
  license: MIT
  modality: text; text
  model_card: https://huggingface.co/NucleusAI/nucleus-22B-token-500B
  monitoring: unknown
  name: Nucleus
  nationality: USA
  organization: Nucleus.AI
  prohibited_uses: Production use without adequate assessment of risks and mitigation;
    any use cases which may be considered irresponsible or harmful.
  quality_control: ''
  size: 22B parameters (dense)
  training_emissions: unknown
  training_hardware: unknown
  training_time: 2 weeks
  type: model
  url: https://www.withnucleus.ai/
