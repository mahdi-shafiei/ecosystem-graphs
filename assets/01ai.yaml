---
- type: model
  name: Yi
  organization: 01 AI
  description: The Yi series models are large language models trained from scratch
    by developers at 01 AI.
  created_date: 2023-11-02
  url: https://github.com/01-ai/Yi
  model_card: https://huggingface.co/01-ai/Yi-34B
  modality: text; text
  analysis: Evaluated on standard language benchmarks, common sense reasoning, and
    reading comprehension in comparison to SoTA LLMs.
  size: 34B parameters (dense)
  dependencies: []
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: Model underwent supervised fine-tuning, leading to a greater
    diversity of responses.
  access: open
  license:
    explanation: Model license can be found at https://huggingface.co/01-ai/Yi-34B/blob/main/LICENSE.
      Code license is under Apache 2.0
    value: custom
  intended_uses: ''
  prohibited_uses: none
  monitoring: unknown
  feedback: https://huggingface.co/01-ai/Yi-34B/discussions
- type: model
  name: Yi-VL
  organization: 01 AI
  description: The Yi Vision Language (Yi-VL) model is the open-source, multimodal
    version of the Yi Large Language Model (LLM) series, enabling content comprehension,
    recognition, and multi-round conversations about images.
  created_date: 2024-01-23
  url: https://github.com/01-ai/Yi
  model_card: https://huggingface.co/01-ai/Yi-VL-34B
  modality: text; text
  analysis: Yi-VL outperforms all existing open-source models in MMMU and CMMMU,
    two advanced benchmarks that include massive multi-discipline multimodal questions
    (based on data available up to January 2024).
  size: 34B parameters (dense)
  dependencies: []
  training_emissions: unknown
  training_time: 10 days
  training_hardware: 128 NVIDIA A800 (80G) GPUs
  quality_control: unknown
  access: open
  license:
    explanation: Model license can be found at https://huggingface.co/01-ai/Yi-VL-34B/blob/main/LICENSE.
      Code license is under Apache 2.0
    value: custom
  intended_uses: ''
  prohibited_uses: ''
  monitoring: unknown
  feedback: https://huggingface.co/01-ai/Yi-VL-34B/discussions
- type: model
  name: Chai-1
  organization: Chai Discovery Team
  description: Chai-1 is a multi-modal foundation model for molecular structure prediction that performs at the state-of-the-art across a variety of tasks relevant to drug discovery. It enables unified prediction of proteins, small molecules, DNA, RNA, covalent modifications, and more. It tested with a 77% success rate on the PoseBusters benchmark and an CÎ± LDDT of 0.849 on the CASP15 protein monomer structure prediction set.
  created_date: 2024-09-09
  url: https://www.chaidiscovery.com/blog/introducting-chai-1
  model_card: 
  modality: Unknown
  analysis: The model was tested across a large number of benchmarks and found to achieve a 77% success rate on the PoseBusters benchmark (vs. 76% by AlphaFold3), as well as an CÎ± LDDT of 0.849 on the CASP15 protein monomer structure prediction set (vs. 0.801 by ESM3-98B). The model can also run in single sequence mode without MSAs while preserving most of its performance.
  size: Unknown
  dependencies: Unknown
  training_emissions: Unknown
  training_time: Unknown
  training_hardware: Unknown
  quality_control: Unknown
  access: The model is available for free via a web interface for commercial applications such as drug discovery and the model weights and inference code are also released as a software library for non-commercial use.
  license: Unknown
  intended_uses: Can be used for drug discovery and other applications that require molecular structure prediction.
  prohibited_uses: Unknown
  monitoring: Unknown
  feedback: Unknown
